{"cells": [{"metadata": {}, "cell_type": "code", "source": "import shutil\ntry:\n    shutil.rmtree('Data')\n    shutil.rmtree('output')\nexcept:\n    print('Directory doesnt exist')", "execution_count": 1, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Downloading data"}, {"metadata": {}, "cell_type": "code", "source": "import os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='mLfby7c4EdgN_6a6QZJqLwTpK64eC2k3GcMHPdW-VC91',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.eu.cloud-object-storage.appdomain.cloud')\n\nbucket = 'digitalnaturalistmodel-donotdelete-pr-u6twiyt8iaxoqc'\nobject_key = 'Digital Naturalist Dataset.zip'\n\nstreaming_body_1 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\n", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Unzipping data folder"}, {"metadata": {}, "cell_type": "code", "source": "from io import BytesIO\nimport zipfile\nunzip = zipfile.ZipFile(BytesIO(streaming_body_1.read()), 'r')\nfile_paths = unzip.namelist()\nfor path in file_paths:\n    unzip.extract(path)", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Data augmentation"}, {"metadata": {}, "cell_type": "code", "source": "from keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom os import listdir\nimport time", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def hms_string(sec_elapsed):\n    h = int(sec_elapsed / (60 * 60))\n    m = int((sec_elapsed % (60 * 60)) / 60)\n    s = sec_elapsed % 60\n    return f\"{h}:{m}:{round(s,1)}\"", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def augment_data(file_dir, n_generated_samples, save_to_dir):\n    data_gen = ImageDataGenerator(rotation_range=30, width_shift_range=0.1, height_shift_range=0.15, shear_range=0.25, zoom_range=0.2, horizontal_flip=True, vertical_flip=False, fill_mode='nearest', brightness_range=(0.5,1.2))\n    for filename in listdir(file_dir):\n        image = cv2.imread(file_dir + '/' + filename)\n        image = image.reshape((1,) + image.shape)\n        save_prefix = 'aug_' + filename[:-4]\n        i = 0\n        for batch in data_gen.flow(x=image, batch_size=1, save_to_dir=save_to_dir,save_prefix=save_prefix, save_format='jpg'):\n            i += 1\n            if i>n_generated_samples:\n                break", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Passing input to augment_data ()"}, {"metadata": {}, "cell_type": "code", "source": "try:\n    os.mkdir('Data')\n    os.mkdir('Data/Bird-Great Indian Bustard Bird')\n    os.mkdir('Data/Bird-Spoon Billed Sandpiper Bird')\n    os.mkdir('Data/Mammal-Pangolin Mammal')\n    os.mkdir('Data/Mammal-Senenca White Deer Mammal')\n    os.mkdir('Data/Flower-Corpse Flower')\n    os.mkdir('Data/Flower-Lady Slipper Orchid Flower')\nexcept:\n    print('Directory already exists')", "execution_count": 7, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "temp = \"\"\"path1 = '/home/wsuser/work/Digital Naturalist Dataset/'\npath2 = '/home/wsuser/work/Data/'\nfor dirc in os.listdir(path1):\n    for dirk in os.listdir(path1+dirc):\n        for pic in os.listdir(path1+dirc+'/'+dirk):\n            shutil.copy(path1+dirc+'/'+dirk+'/'+pic,path2+dirc+'-'+dirk+'/'+pic)\"\"\"", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "start_time = time.time()\naugmented_data_path = '/home/wsuser/work/Data/'\n\n#Birds\naugment_data(file_dir='/home/wsuser/work/Digital Naturalist Dataset/Bird/Great Indian Bustard Bird' , n_generated_samples=8, save_to_dir=augmented_data_path+'Bird-Great Indian Bustard Bird')\naugment_data(file_dir='/home/wsuser/work/Digital Naturalist Dataset/Bird/Spoon Billed Sandpiper Bird' , n_generated_samples=8, save_to_dir=augmented_data_path+'Bird-Spoon Billed Sandpiper Bird')\n \n#Mammals\naugment_data(file_dir='/home/wsuser/work/Digital Naturalist Dataset/Mammal/Pangolin Mammal' , n_generated_samples=8, save_to_dir=augmented_data_path+'Mammal-Pangolin Mammal')\naugment_data(file_dir='/home/wsuser/work/Digital Naturalist Dataset/Mammal/Senenca White Deer Mammal' , n_generated_samples=8, save_to_dir=augmented_data_path+'Mammal-Senenca White Deer Mammal')\n\n#Flowers\naugment_data(file_dir='/home/wsuser/work/Digital Naturalist Dataset/Flower/Corpse Flower' , n_generated_samples=8, save_to_dir=augmented_data_path+'Flower-Corpse Flower')\naugment_data(file_dir='/home/wsuser/work/Digital Naturalist Dataset/Flower/Lady Slipper Orchid Flower' , n_generated_samples=8, save_to_dir=augmented_data_path+'Flower-Lady Slipper Orchid Flower')\n\nend_time = time.time()\nexecution_time = end_time - start_time\nprint(f\"Elapsed Time: {hms_string(execution_time)}\")", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "Elapsed Time: 0:0:13.9\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "# Train-Test Split"}, {"metadata": {}, "cell_type": "code", "source": "%pip install split-folders\nimport splitfolders\nsplitfolders.ratio('/home/wsuser/work/Data/', output=\"output\", seed=1337, ratio=(.8, 0.1,0.1)) ", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: split-folders in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (0.5.1)\nNote: you may need to restart the kernel to use updated packages.\n", "name": "stdout"}, {"output_type": "stream", "text": "Copying files: 1250 files [00:00, 7753.86 files/s]\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "markdown", "source": "# Image Augmentation"}, {"metadata": {}, "cell_type": "code", "source": "from tensorflow.keras.preprocessing.image import ImageDataGenerator", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "train_generator = ImageDataGenerator()\ntest_generator = ImageDataGenerator()", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "x_train = train_generator.flow_from_directory(r\"/home/wsuser/work/output/train\", target_size = (64,64), class_mode = 'categorical', batch_size = 24)\nx_val = train_generator.flow_from_directory(r\"/home/wsuser/work/output/val\", target_size = (64,64), class_mode = 'categorical', batch_size = 24)\nx_test = test_generator.flow_from_directory(r\"/home/wsuser/work/output/test\", target_size = (64,64), class_mode = 'categorical', batch_size = 24)", "execution_count": 13, "outputs": [{"output_type": "stream", "text": "Found 998 images belonging to 6 classes.\nFound 121 images belonging to 6 classes.\nFound 131 images belonging to 6 classes.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "x_train.class_indices", "execution_count": 14, "outputs": [{"output_type": "execute_result", "execution_count": 14, "data": {"text/plain": "{'Bird-Great Indian Bustard Bird': 0,\n 'Bird-Spoon Billed Sandpiper Bird': 1,\n 'Flower-Corpse Flower': 2,\n 'Flower-Lady Slipper Orchid Flower': 3,\n 'Mammal-Pangolin Mammal': 4,\n 'Mammal-Senenca White Deer Mammal': 5}"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "ls -n output/val/'Bird-Great Indian Bustard Bird'", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "total 192\r\n-rw-rw---- 1 1000 103000 8429 Nov 11 18:17  aug_download_0_6556.jpg\r\n-rw-rw---- 1 1000 103000 9502 Nov 11 18:17  aug_download_0_7120.jpg\r\n-rw-rw---- 1 1000 103000 8300 Nov 11 18:17 'aug_download (10)_0_9528.jpg'\r\n-rw-rw---- 1 1000 103000 8601 Nov 11 18:17 'aug_download (1)_0_5090.jpg'\r\n-rw-rw---- 1 1000 103000 9041 Nov 11 18:17 'aug_download (2)_0_4751.jpg'\r\n-rw-rw---- 1 1000 103000 7299 Nov 11 18:17 'aug_download (3)_0_9637.jpg'\r\n-rw-rw---- 1 1000 103000 8840 Nov 11 18:17 'aug_download (6)_0_130.jpg'\r\n-rw-rw---- 1 1000 103000 6994 Nov 11 18:17 'aug_download (7)_0_8398.jpg'\r\n-rw-rw---- 1 1000 103000 7159 Nov 11 18:17 'aug_download (7)_0_847.jpg'\r\n-rw-rw---- 1 1000 103000 9397 Nov 11 18:17 'aug_download (8)_0_9654.jpg'\r\n-rw-rw---- 1 1000 103000 4593 Nov 11 18:17 'aug_download (9)_0_1290.jpg'\r\n-rw-rw---- 1 1000 103000 7442 Nov 11 18:17 'aug_images (1)_0_1910.jpg'\r\n-rw-rw---- 1 1000 103000 4959 Nov 11 18:17 'aug_images (2)_0_4637.jpg'\r\n-rw-rw---- 1 1000 103000 9277 Nov 11 18:17 'aug_images (4)_0_9969.jpg'\r\n-rw-rw---- 1 1000 103000 8419 Nov 11 18:17 'aug_images (5)_0_1996.jpg'\r\n-rw-rw---- 1 1000 103000 8889 Nov 11 18:17 'aug_images (5)_0_8774.jpg'\r\n-rw-rw---- 1 1000 103000 6958 Nov 11 18:17 'aug_images (6)_0_2890.jpg'\r\n-rw-rw---- 1 1000 103000 5358 Nov 11 18:17 'aug_images (7)_0_1267.jpg'\r\n-rw-rw---- 1 1000 103000 5144 Nov 11 18:17 'aug_images (7)_0_1390.jpg'\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "# Creating the model"}, {"metadata": {}, "cell_type": "code", "source": "from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense\nfrom tensorflow.keras import regularizers", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model = Sequential() #Initializing sequential model3", "execution_count": 82, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Adding layers"}, {"metadata": {}, "cell_type": "code", "source": "model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(64,64,3)))  #Convolution layer\nmodel.add(MaxPooling2D(pool_size=(2,2)))  #MaxPooling layer\nmodel.add(Flatten())  #Flatten layer\nmodel.add(Dense(275,activation='relu',kernel_regularizer=regularizers.L2(0.1)))  #Hidden layer 1\nmodel.add(Dense(130,activation='relu',kernel_regularizer=regularizers.L2(0.01)))  #Hidden layer 2\nmodel.add(Dense(50,activation='relu',kernel_regularizer=regularizers.L2(0.001))) #Hidden layer 3\nmodel.add(Dense(6,activation='softmax')) #Output layer", "execution_count": 83, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Compile the Model"}, {"metadata": {}, "cell_type": "code", "source": "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.summary()", "execution_count": 84, "outputs": [{"output_type": "stream", "text": "Model: \"sequential_11\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_10 (Conv2D)          (None, 62, 62, 32)        896       \n                                                                 \n max_pooling2d_10 (MaxPoolin  (None, 31, 31, 32)       0         \n g2D)                                                            \n                                                                 \n flatten_10 (Flatten)        (None, 30752)             0         \n                                                                 \n dense_40 (Dense)            (None, 275)               8457075   \n                                                                 \n dense_41 (Dense)            (None, 130)               35880     \n                                                                 \n dense_42 (Dense)            (None, 50)                6550      \n                                                                 \n dense_43 (Dense)            (None, 6)                 306       \n                                                                 \n=================================================================\nTotal params: 8,500,707\nTrainable params: 8,500,707\nNon-trainable params: 0\n_________________________________________________________________\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\nearly_stopping = EarlyStopping(monitor='val_accuracy',patience=3)\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy',patience=3,factor=0.5,min_lr=0.00001)\n\ncallback = [reduce_lr,early_stopping]", "execution_count": 85, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model.fit(x_train, steps_per_epoch=len(x_train), epochs=30, validation_data=x_val, validation_steps=len(x_val), callbacks = callback)", "execution_count": 86, "outputs": [{"output_type": "stream", "text": "Epoch 1/30\n42/42 [==============================] - 7s 153ms/step - loss: 213.0748 - accuracy: 0.3647 - val_loss: 48.7334 - val_accuracy: 0.4876 - lr: 0.0010\nEpoch 2/30\n42/42 [==============================] - 6s 152ms/step - loss: 39.7150 - accuracy: 0.6323 - val_loss: 35.5026 - val_accuracy: 0.5124 - lr: 0.0010\nEpoch 3/30\n42/42 [==============================] - 6s 151ms/step - loss: 29.4368 - accuracy: 0.7926 - val_loss: 27.4529 - val_accuracy: 0.5372 - lr: 0.0010\nEpoch 4/30\n42/42 [==============================] - 6s 152ms/step - loss: 23.3615 - accuracy: 0.8778 - val_loss: 22.7443 - val_accuracy: 0.5207 - lr: 0.0010\nEpoch 5/30\n42/42 [==============================] - 6s 152ms/step - loss: 19.1763 - accuracy: 0.9339 - val_loss: 19.2045 - val_accuracy: 0.6198 - lr: 0.0010\nEpoch 6/30\n42/42 [==============================] - 7s 156ms/step - loss: 16.2808 - accuracy: 0.9309 - val_loss: 16.4855 - val_accuracy: 0.6116 - lr: 0.0010\nEpoch 7/30\n42/42 [==============================] - 7s 157ms/step - loss: 14.0340 - accuracy: 0.9639 - val_loss: 14.6551 - val_accuracy: 0.5950 - lr: 0.0010\nEpoch 8/30\n42/42 [==============================] - 6s 154ms/step - loss: 12.2018 - accuracy: 0.9419 - val_loss: 12.9489 - val_accuracy: 0.5868 - lr: 0.0010\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 86, "data": {"text/plain": "<keras.callbacks.History at 0x7fe8ac83e5e0>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "a = model.evaluate_generator(x_test, len(x_test))", "execution_count": 87, "outputs": [{"output_type": "stream", "text": "/tmp/wsuser/ipykernel_64086/1516118933.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n  a = model.evaluate_generator(x_test, len(x_test))\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "code", "source": "print(f'Error: {a[0]}')\nprint(f'Accuracy: {a[1]}')", "execution_count": 88, "outputs": [{"output_type": "stream", "text": "Error: 12.807180404663086\nAccuracy: 0.6259542107582092\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "model.save('model1.h5')", "execution_count": 67, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}